{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marxe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marxe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from heapq import nlargest\n",
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Ontologia, o ramo da Filosofia em que tratamos de esclarecer em que consiste dizer que algo existe, ou que é real, à diferença de ficções (os números, por exemplo, existem?).Um físico que reflete sobre o que seja ciência, um engenheiro que o faz sobre a natureza da tecnologia, um pintor que pensa o propósito da criação, são melhores profissionais.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texto = input(\"Insira o texto para ser resumido: \")\n",
    "\n",
    "if texto.count(\". \") > 20:\n",
    "    comprimento = int(round(texto.count(\". \")/10, 0))\n",
    "else:\n",
    "    comprimento = 1 \n",
    "\n",
    "# if texto.count(\". \") > 20: Está linha verifica se o número de ocorrencias de pontos finais seguidos por um espaço (\". \") no texto é maior que 20\n",
    "    \n",
    "# Em seguida vem o calculo do comprimento que seria comprimento = int(round(texto.count(\". \")/10, 0)) que se a condição acima for verdadeira, o código calcula o comprimento dividindo o número de ocorrencias  de \". \" por 10 e arredondando para o inteiro mais proximo. Isso sugere que, quando há muitos pontos finais no texto, o comprimento do resumo desejado é determinado por uma fração dessa contagem\n",
    "    \n",
    "# Se o número de ocorrencias de \". \" no texto não for maior que 20, o comprimento do resumo é simplesmente definido como 1\n",
    "    \n",
    "nopunch = [caracteres for caracteres in texto if caracteres not in string.punctuation]\n",
    "nopunch = \"\".join(nopunch)\n",
    "\n",
    "# Nesse trecho o codigo está criando uma nova string chamada nopunch que contem todos os caracteres da variavel texto, mas excluindo os caracteres da pontuação. nopunch = [caracteres for caracteres in texto if caractres not in string.punctuation], essa linha utiliza uma list comprehension para criar uma lista chamada nopunch. Ela percorre cada caractere na string texto e adiciona apenas os caracteres que não estão na string pontuação string.punctuation. \n",
    "\n",
    "# Junção dos caracteres para formar uma nova string, nopunch = \"\".join(nopunch) esta linha utiliza o metodo join para concatenar todos os caracteres presentes na lista nopunch e formar uma nova string. O metodo join é chamado na string vazia \"\", o que significa que nenhum caractere adicional será inserido entre os caracteres da lista ao serem concatenados. Dessa forma, ao final deste trecho de código, a variavel nopunch contera a string original texto, mas sem os caractres de pontuação\n",
    "\n",
    "texto_processado =  [palavra for palavra  in nopunch.split() if palavra.lower() not in nltk.corpus.stopwords.words(\"english\")]\n",
    "\n",
    "# nopunch.split() nopunch é a string que criamos anteriormente, sem os caracteres de pontuação. A função split() dividee essa string em uma lista de palavras, por padrão ela separa a sting pelos espaços em branco\n",
    "\n",
    "# for palavra in... isso percorre cada palavra na lista de palavras resultante da operação split()\n",
    "\n",
    "#  if palavra.lower() not int nltk.corpus.stopwrods.words(\"english\") >>> palavra.lower() transforma a palavra para minusculas para garantir uma comparação sem distinção entre maiusculas e minusculas, nltk.corpus.stopwords.words(\"english\") isso representa a lista de palavras de parada (stopwords) em ingles do pacote NLTK. Stopwords são palavras comuns que geralmente são removidas em tarefas e processamento de texto, pois não contribuem muito para o significado.\n",
    "\n",
    "# a condição if verifica se a palavra (em minusculas) não está na lista de stopwrods em ingles. Se a palavra não for uma stopword ela é incluida na lista.\n",
    "\n",
    "PalavrasComFrequencia = {}\n",
    "\n",
    "# Aqui está sendo criado um dicionario para armazenar a contagem de frequencia de cada palavra na lista texto_processado\n",
    "\n",
    "for palavra in texto_processado:\n",
    "    if palavra not in PalavrasComFrequencia:\n",
    "        PalavrasComFrequencia[palavra] = 1\n",
    "    else:\n",
    "        PalavrasComFrequencia[palavra] = PalavrasComFrequencia[palavra] + 1\n",
    "\n",
    "# for palavra in texto_processado: itera sobre cada palavra na lista texto_processado\n",
    "\n",
    "# if palavra not in PalavrasComFrequencia >>> Verifica se a palavra não está presente no dicionario PalavrasComFrequencia, se a palavra não estiver no dicionário, significa que é a primeira vez que encontramos essa palavra. PalvrasComFrequencia[palavra] = 1 >>> Se a palavra não estiver no dicionário, ela é adicionada como uma chave, e o valor associado a essa chave é inicializado como 1, indicando que esta é a primeira ocorrencia da palavra \n",
    "        \n",
    "# else: PalavrasComFrquencia[palavra] = PalavrasComFrequencia[palavra] + 1 >>> Se a palavra já estiver no dicionario, o bloco else é executado. Isso significa que já encontramos essa palavra antes. Nesse caso, incrmentamos o valor associado a essa chave no dicionario, indicando que encontramos a palavra novamente. Desta forma, ao final do codigo, o dicionario PalavrasComFrquencia, contém todas as palavras unicas encontradas em texto_processado como chaves, e os valores associados a essas chaves representam a contagem de frequencia de cada palavra no texto. Esse é um passo comum ao realizar análise de texto para entender a distribuição das palavras.\n",
    "        \n",
    "MaxFrequencia = max(PalavrasComFrequencia.values())\n",
    "\n",
    "for palavra in PalavrasComFrequencia.keys():\n",
    "    PalavrasComFrequencia[palavra] = (PalavrasComFrequencia[palavra]/MaxFrequencia)\n",
    "\n",
    "# for palavra in PalavrasComFrequencia.keys() >>> Esse loop for itera sobre as chaves (palavras) no dicionario PalavrasComFrequencia, PalavrasComFrequencia[palavra]/MaxFrequencia, para cada palavra no dicionario, a frquencia da aplavra é normalizada dividindo a pela frequencia maxima MaxFrenquencia. A normalização é realizada para transformar as contagens absolutas em proporções relativas, garantindo que todas as frequencias estejam na faixa de 0 a 1\n",
    "\n",
    "\n",
    "sent_list = nltk.sent_tokenize(texto)\n",
    "\n",
    "# Inicializa um dicionário vazio para armazenar as pontuações de cada sentença\n",
    "\n",
    "sent_score = {}\n",
    "\n",
    "# Itera sobre cada sentença\n",
    "for sentenca in sent_list:\n",
    "    # Tokeniza a sentença em palavras\n",
    "    palavras = nltk.word_tokenize(sentenca)\n",
    "\n",
    "    # Itera sobre cada palavra na sentença\n",
    "    for palavra in palavras:\n",
    "        # Verifica se a palavra está no dicionário PalavrasComFrequencia\n",
    "        if palavra in PalavrasComFrequencia.keys():\n",
    "            # Verifica se a sentença não está no dicionário sent_score\n",
    "            if sentenca not in sent_score.keys():\n",
    "                sent_score[sentenca] = PalavrasComFrequencia[palavra]\n",
    "            else:\n",
    "                sent_score[sentenca] += PalavrasComFrequencia[palavra]\n",
    "\n",
    "# Agora você tem um dicionário sent_score contendo as pontuações de cada sentença\n",
    "                \n",
    "Resumindo_o_Texto = nlargest(comprimento, sent_score, key=sent_score.get)\n",
    "Resumo = \"\".join(Resumindo_o_Texto)\n",
    "\n",
    "print(Resumo)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
